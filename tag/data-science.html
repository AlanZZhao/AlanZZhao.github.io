<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Alan Zhao | articles tagged "data science"</title>
    <link rel="shortcut icon" type="image/png" href="http://alanzzhao.com/favicon.png">
    <link rel="shortcut icon" type="image/x-icon" href="http://alanzzhao.com/favicon.ico">
    <link href="http://alanzzhao.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Alan Zhao Full Atom Feed" />
    <link rel="stylesheet" href="http://alanzzhao.com/theme/css/screen.css" type="text/css" />
    <link rel="stylesheet" href="http://alanzzhao.com/theme/css/pygments.css" type="text/css" />
    <link rel="stylesheet" href="http://alanzzhao.com/theme/css/print.css" type="text/css" media="print" />
    <meta name="generator" content="Pelican" />
    <meta name="description" content="" />
    <meta name="author" content="Alan Zhao" />
</head>
<body>
    <header>
        <nav>
            <ul>
                <li class="ephemeral selected"><a href="http://alanzzhao.com/tag/data-science.html">data science</a></li>
                <li><a href="http://alanzzhao.com/">Home</a></li>
                <li><a href="http://alanzzhao.com/pages/about.html">About</a></li>
                <li><a href="https://linkedin.com/in/alanzzhao">LinkedIn</a></li>
                <li><a href="http://stackoverflow.com/users/4967110/azhao?tab=profile">StackOverflow</a></li>
                <li><a href="http://alanzzhao.com/archives">Archives</a></li>
            </ul>
        </nav>
        <div class="header_box">
            <h1><a href="http://alanzzhao.com/">Alan Zhao</a></h1>
        </div>
    </header>
    <div id="wrapper">
        <div id="content">            <h4 class="date">Mar 02, 2018</h4>

            <article class="post">
                <h2 class="title">
                    <a href="http://alanzzhao.com/driven_data_competition.html" rel="bookmark" title="Permanent Link to &quot;Driven Data Poverty Prediction Challenge&quot;">Driven Data Poverty Prediction Challenge</a>
                </h2>

                
                

                <p>For the past month, I worked on a <a href="https://www.drivendata.org/competitions/50/worldbank-poverty-prediction/page/97/">Driven Data Competition - Predicting Poverty</a> alongside <a href="https://www.linkedin.com/in/shadiekhubba/">Shadie Khubba (Yale Statistics MSc '18)</a>. This post is a detailing of our results (top 10% finish ~ 200 place of 2200 contestants, code, and learnings.</p>
<p>Our code for our best models can be found on our <a href="https://github.com/AlanZZhao/driven_data">repo</a>.</p>
<h3>Motivation</h3>
<p>Shadie and I had met in a Statistical Case Studies class that involved weekly hack session of solving an amorphous problem (e.g. predict New Haven housing from online data). We figured this Driven Data Competition was our attempt to prove our chops in the real world and get more familiar with the Python data stack as opposed to academia's R. Plus the bragging rights and possible $ if we won.</p>
<h3>The Problem</h3>
<p>According to the <a href="https://www.drivendata.org/competitions/50/worldbank-poverty-prediction/page/99/">competition website</a>, predicting poverty from survey data is a hard problem. We were given survey response data from 3 anonymized countries (A, B &amp; C), at both the household and individual level. Predictions were done at the household level, with each household having a 1:n relationship with individuals.</p>
<p>Scoring was done with a mean log loss of the three, with our predictions being offered as probabilities between 0-1 for each household being classified as poor. A baseline naive score with uniform 0.5 probability would score 0.69.</p>
<h3>Early Learnings</h3>
<p>We spent our first two weeks in a traditional approach; conducting exploratory data analysis and throwing some standard classifiers at the data. Exploratory data did not prove particularly useful since each column had its data scrambled and normalized. However, two challenging issues emerged from looking at the data. First, the classes were imbalanced in countries B and C, in particular poor households had 1:12 ratio with non-poor households. Second, the majority &gt;90% of predictors were categorical; with several having large sets of up to 80 possible values.</p>
<p>We began throwing traditional methods at it: SVM, Logistic Regression, Boosting and building off the Random Forest model benchmark (scored at .55). Only one - Logistic Regression brought us into a competitive range of .27. At the time, scoreboard leaders were in the neighborhood of .15.</p>
<p>Organizationally, we started with a GitHub repo that quickly turned into a mess. While we did organize our work with all data files/submission files saved, it quickly grew apparent that restructuring our code was inefficient. Shadie and I were working in our separate .py files, and often rewriting or re-running models locally ourselves. We didn't enough time planning a project structure early on; later I found out about the <a href="https://drivendata.github.io/cookiecutter-data-science/#cookiecutter-data-science">cookie-cutter data science project</a>, but it was too late to implement a new project structure.</p>
<h3>Inherent Challenges</h3>
<p>While we solved some minor problems with imbalanced classes (resampling) and missing values (imputation) but we really struggled with two major problems.</p>
<h4>Categorical Variables</h4>
<p>We needed a way to convert the categorical variables into numerical data such that scikit learn could actually use it as an input space. We started with one hot encoding (turning each possible value of a categorical predictor into a new 0/1 predictor), but realized it was blowing up dimensionality of the feature space. Our 50 categorical variables were turning into 500 and the curse of dimensionality was taking effect: additional useless variables being added in and getting some assignment of weight. We spent time early on trying to find the right heuristics to reduce the dimensionality.</p>
<h4>Utilizing Individual Data</h4>
<p>We began by using household data since it was provided. Incorporating summary statistics (e.g. mean, var, max, min) of predictions on individual data actually worsened prediction performance. Our hypothesis here is that individual predictions were offering a noisier version of what the household data already provided. Posts on the forum suggested that this was a common hurdle for the entire competitor field - many people were getting .17-.18 results just as we had by only using the household data.</p>
<h3>CatBoost</h3>
<p><img alt="CatBoost representation" src="https://avatars.mds.yandex.net/get-bunker/120922/58e11eb206a498bbea44041cb3d7e5e2e181c6ae/orig"></p>
<p>We made a lucky breakthrough into the top 10% with a discovery of <a href="https://tech.yandex.com/catboost/">CatBoost</a>. CatBoost is a GBM variant made by Russian search giant Yandex, and it's killer feature is native support for categorical variables (hence the name categorical boosting = catboost). CatBoost is able to use statistical methods to selectively keep the most predictive values in each categorical column; saving much tedious cleaning on our end.</p>
<p>Our first submission here brought us in the top 8% of submissions, showing that boosting is the way to go. This dramatic improvement came solely from avoiding the curse of dimensionality!</p>
<p>However we couldn't significantly improve this data. We numerous feature engineering approaches for the individual data, but were stumped. We ended up in the 200th place of over 2200 competitors though, so not a bad showing for our first time out.</p>
<h3>Lessons Learned</h3>
<p>We learned a lot of neat technical tricks and tools (cookiecutter, catboost, scikit learn goodies like pipeline), but the real learnings are far more generally applicable.</p>
<h4>Try Boosting First</h4>
<p>We spent a lot of time tossing models that didn't pan out before we arrived at the correct one. From the post-competition discussion boards, we realized that many kaggle-vets immediately tried industry standard models (XGBoost, LightBoost, CatBoost) as their first model as a matter of habit. Readings online support this idea that boosting is the go-to black box solution.</p>
<h4>Feature Engineering is Everything</h4>
<p>We couldn't get beyond our initial gain from using CatBoost by adding in individual data, though we tried many many different approaches ranging from feature selection based off importance, predictions from individual data as features and more.</p>
<p>The big question was how to build features from the individual data. One of the top 3 finishers posted his feature set, and it turned out to be ridiculously simply: counting positive and negative values, the individual id of individuals (suggesting some ordering to household), sum of continuous values, and a count of unqiue categorical values.</p>
<h4>Build a Testing Harness</h4>
<p>A major challenge here was that we underestimated the limitations imposed by the two submissions per day. We were foolish and started off building models and then submitting to validate results. Only after many unfortunate submissions did we build out a suite of validation tools to rigorously test locally first. By the end of the first two weeks, we were running 3-fold cross validation, and eyeballing confusion matrices and predicted probability distributions. We started by treating the competition's submissions as a last validation step, not as a first one.</p>
<h3>Next Time &amp; Real World Application</h3>
<p>I'm optimistic that the next time we partake in a kaggle-style competition, we could place much higher if we had course corrected on these three things. Instead of scrambling to build out a testing harness with two weeks left, or furiously creating additional features in the final days, we could have comfortably spent 3 weeks feature engineering. The competition often felt like the xkcd comic below, but if we did it again, one would hope the pile of linear algebra would be less messy, and the results easier to check.</p>
<p><img src="https://imgs.xkcd.com/comics/machine_learning_2x.png" alt="Summary XKCD comic" width="300"/></p>
<p>A final takeaway for both of us is that real data science life is not a kaggle-style competition. Online competitions push for a best solution; day-to-day work demands the "good enough" solution.</p>
<p>I'd imagine that the World Bank, which sponsored this competition, would have been equally happy to know that household data and an out of the box GBM produce a solution within .03 of the winning one. Putting together the $15,000 prize and paying DrivenData to run the competition shows they likely didn't know this from the get go. Clearly, still some quick wins to be found in social sector data challenges.</p>
                <div class="clear"></div>

                <div class="info">
                    <a href="http://alanzzhao.com/driven_data_competition.html">posted at 09:20</a>
                    &nbsp;&middot;&nbsp;<a href="http://alanzzhao.com/category/blog.html" rel="tag">Blog</a>
                    &nbsp;&middot;
                    &nbsp;<a href="http://alanzzhao.com/tag/python.html" class="tags">python</a>
                    &nbsp;<a href="http://alanzzhao.com/tag/learning.html" class="tags">learning</a>
                    &nbsp;<a href="http://alanzzhao.com/tag/data-science.html" class="tags selected">data science</a>
                </div>
            </article>

        </div>
        <div class="clear"></div>
    </div>
    <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>
    <script type="text/javascript">
    try {
        var pageTracker = _gat._getTracker("UA-79885167-1");
    pageTracker._trackPageview();
    } catch(err) {}</script>
</body>
</html>